{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_deltaprot_designs_data():\n",
    "\n",
    "    no_disulfide_df =pd.read_csv(\"/home/tadas/code/single_chain_dp_bristol/selected_deltaprots/no_disulfide/no_disulfide_selected_deltaprots.csv\")\n",
    "    variable_linkers_df = pd.read_csv(\"/home/tadas/code/single_chain_dp_bristol/selected_deltaprots/variable_linkers/variable_linkers/variable_linkers_selected_deltaprots.csv\")\n",
    "\n",
    "    no_disulfide_df[\"name\"]=\"no_disulfide_\"+no_disulfide_df[\"orientation_code\"]\n",
    "    variable_linkers_df[\"name\"]=\"variable_linkers_\"+variable_linkers_df[\"orientation_code\"]\n",
    "\n",
    "    # merge the two piplene dataframes \n",
    "    df = pd.concat([no_disulfide_df, variable_linkers_df], axis=0)\n",
    "\n",
    "    well_df = pd.read_csv(\"/home/tadas/code/single_chain_dp_bristol/order_optimised_codons_96_wp.csv\")\n",
    "\n",
    "    # merge well_df with df by Name and sort by Well Position\n",
    "    df = pd.merge(well_df, df, how=\"left\", left_on=\"Name\", right_on=\"name\")\n",
    "    df.to_csv(\"/home/tadas/code/single_chain_dp_bristol/deltaprot_designs_data.csv\", index=False)\n",
    "\n",
    "def load_deltaprot_designs_data():\n",
    "    return pd.read_csv(\"/home/tadas/code/single_chain_dp_bristol/deltaprot_designs_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_deltaprot_designs_data()\n",
    "df = load_deltaprot_designs_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df \n",
    "# populate received_from_idt column. Received everything except for C2,C4,D5,D6,F2,F3,F6\n",
    "not_received = ['C2', 'C4', 'D5', 'D6', 'F2', 'F3', 'F6']\n",
    "df['received_from_idt'] = ~df[\"Well Position\"].isin(not_received)\n",
    "\n",
    "# populate transformation_attempted for (A1-A12,B1-B12,C1,C3,F4,C5,C6)\n",
    "attempted_ids = set([f\"A{i}\" for i in range(1, 13)] +\n",
    "                    [f\"B{i}\" for i in range(1, 13)] +\n",
    "                    ['C1', 'C3', 'F4', 'C5', 'C6'])\n",
    "df['transformation_attempted'] = df[\"Well Position\"].isin(attempted_ids)\n",
    "df['transformation_successful'] = df[\"Well Position\"].apply(\n",
    "    lambda x: (False if x == 'C6' else True) if x in attempted_ids else np.nan\n",
    ")\n",
    "\n",
    "# populate tranformation_successful for transformation_attempted only (otherwise none), but false for C6\n",
    "df['transformation_successful'] = df[\"Well Position\"].apply(\n",
    "    lambda x: (False if x == 'C6' else True) if x in attempted_ids else np.nan\n",
    ")\n",
    "\n",
    "\n",
    "# populate expression_levels: (None, \"low\",\"medium\",\"high\") low: A1,A3,A6,A7,A8,A10,B1. Medium: A5,A11,B2,B3. High: A9,A12\n",
    "expr_map = {\n",
    "    **dict.fromkeys(['A1', 'A3', 'A6', 'A7', 'A8', 'A10', 'B1'], 'low'),\n",
    "    **dict.fromkeys(['A5', 'A11', 'B2', 'B3'], 'medium'),\n",
    "    **dict.fromkeys(['A9', 'A12'], 'high')\n",
    "}\n",
    "df['expression_levels'] = df[\"Well Position\"].map(expr_map)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save df to csv\n",
    "df.to_csv(\"/home/tadas/code/single_chain_dp_bristol/experimental_results/deltaprot_designs_data_with_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Assuming 'df' is your DataFrame and it includes a categorical 'expression_levels'\n",
    "# Identify all numeric columns in the dataframe\n",
    "numeric_columns = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "# 1. Box Plots for each numeric feature\n",
    "for col in numeric_columns:\n",
    "    print(col)\n",
    "    plt.figure(figsize=(4,3))\n",
    "    sns.boxplot(x='expression_levels', y=col, data=df)\n",
    "    sns.swarmplot(x='expression_levels', y=col, data=df)\n",
    "    plt.title(f'Box Plot of {col} by Expression Levels')\n",
    "    plt.show()\n",
    "\n",
    "# # 2. Violin Plots for each numeric feature\n",
    "# for col in numeric_columns:\n",
    "#     plt.figure(figsize=(6,4))\n",
    "#     sns.violinplot(x='expression_levels', y=col, data=df)\n",
    "#     plt.title(f'Violin Plot of {col} by Expression Levels')\n",
    "#     plt.show()\n",
    "\n",
    "# # 3. Scatter Plot Matrix (Pairplot)\n",
    "# sns.pairplot(df, hue='expression_levels', vars=numeric_columns)\n",
    "# plt.show()\n",
    "\n",
    "# # 4. Faceted Histograms using seaborn's FacetGrid for one numeric feature example:\n",
    "# g = sns.FacetGrid(df, col=\"expression_levels\", col_wrap=4, height=3)\n",
    "# g.map(plt.hist, numeric_columns[0], bins=20)\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
